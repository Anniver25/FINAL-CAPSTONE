<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7339e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('g.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data - remove null values\n",
    "print(f\"Original data points: {len(df)}\")\n",
    "df_clean = df.dropna()\n",
    "print(f\"After cleaning: {len(df_clean)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify at least 100 clean records\n",
    "assert len(df_clean) >= 100, \"Dataset must have at least 100 points after cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional bonus: Remove outliers\n",
    "z_scores = stats.zscore(df_clean.select_dtypes(include=[np.number]))\n",
    "df_clean = df_clean[(np.abs(z_scores) < 3).all(axis=1)]\n",
    "print(f\"After outlier removal: {len(df_clean)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9dde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy Operations\n",
    "print(\"\\nNumPy Operations:\")\n",
    "# 1. Mean, Median, Std of Total Waste\n",
    "print(\"1. Total Waste stats:\")\n",
    "print(f\"   Mean: {np.mean(df_clean['Total Waste (Tons)']):.2f}, Median: {np.median(df_clean['Total Waste (Tons)']):.2f}, Std: {np.std(df_clean['Total Waste (Tons)']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7755040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalize Economic Loss\n",
    "scaler = StandardScaler()\n",
    "econ_scaled = scaler.fit_transform(df_clean[['Economic Loss (Million $)']])\n",
    "print(\"2. Scaled Economic Loss (first 5):\", econ_scaled[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6132a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Reshape a matrix\n",
    "matrix = df_clean[['Total Waste (Tons)', 'Population (Million)']].values.reshape(-1, 2)\n",
    "print(\"3. Reshaped matrix shape:\", matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Log transformation\n",
    "log_waste = np.log(df_clean['Total Waste (Tons)'])\n",
    "print(\"4. Log Waste (first 5):\", log_waste[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Random sampling\n",
    "sample = df_clean.sample(5, random_state=1)\n",
    "print(\"5. Random Sample:\")\n",
    "print(sample[['Country', 'Total Waste (Tons)', 'Economic Loss (Million $)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciPy Operation: Pearson Correlation\n",
    "r, p = stats.pearsonr(df_clean['Avg Waste per Capita (Kg)'], df_clean['Economic Loss (Million $)'])\n",
    "print(f\"\\nSciPy Correlation: r = {r:.3f}, p = {p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels: OLS Regression\n",
    "X = sm.add_constant(df_clean['Avg Waste per Capita (Kg)'])\n",
    "y = df_clean['Economic Loss (Million $)']\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(\"\\nStatsmodels OLS Summary:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Histogram of Waste per Capita\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df_clean['Avg Waste per Capita (Kg)'], kde=True, bins=20)\n",
    "plt.title('Distribution of Waste per Capita')\n",
    "plt.xlabel('Kg per Capita')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19694632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Boxplot by Food Category\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Food Category', y='Total Waste (Tons)', data=df_clean)\n",
    "plt.title('Waste by Food Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Visualization: Pairplot\n",
    "sns.pairplot(df_clean[['Total Waste (Tons)', 'Economic Loss (Million $)', 'Avg Waste per Capita (Kg)', 'Population (Million)']])\n",
    "plt.suptitle('Pairwise Relationships', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d93b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot with regression line\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.regplot(x='Total Waste (Tons)', y='Economic Loss (Million $)', data=df_clean,\n",
    "            scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.title('Total Waste vs Economic Loss')\n",
    "plt.xlabel('Total Waste (Tons)')\n",
    "plt.ylabel('Economic Loss (Million $)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae1742",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7339e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('g.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data - remove null values\n",
    "print(f\"Original data points: {len(df)}\")\n",
    "df_clean = df.dropna()\n",
    "print(f\"After cleaning: {len(df_clean)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify at least 100 clean records\n",
    "assert len(df_clean) >= 100, \"Dataset must have at least 100 points after cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional bonus: Remove outliers\n",
    "z_scores = stats.zscore(df_clean.select_dtypes(include=[np.number]))\n",
    "df_clean = df_clean[(np.abs(z_scores) < 3).all(axis=1)]\n",
    "print(f\"After outlier removal: {len(df_clean)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9dde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy Operations\n",
    "print(\"\\nNumPy Operations:\")\n",
    "# 1. Mean, Median, Std of Total Waste\n",
    "print(\"1. Total Waste stats:\")\n",
    "print(f\"   Mean: {np.mean(df_clean['Total Waste (Tons)']):.2f}, Median: {np.median(df_clean['Total Waste (Tons)']):.2f}, Std: {np.std(df_clean['Total Waste (Tons)']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7755040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalize Economic Loss\n",
    "scaler = StandardScaler()\n",
    "econ_scaled = scaler.fit_transform(df_clean[['Economic Loss (Million $)']])\n",
    "print(\"2. Scaled Economic Loss (first 5):\", econ_scaled[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6132a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Reshape a matrix\n",
    "matrix = df_clean[['Total Waste (Tons)', 'Population (Million)']].values.reshape(-1, 2)\n",
    "print(\"3. Reshaped matrix shape:\", matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Log transformation\n",
    "log_waste = np.log(df_clean['Total Waste (Tons)'])\n",
    "print(\"4. Log Waste (first 5):\", log_waste[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Random sampling\n",
    "sample = df_clean.sample(5, random_state=1)\n",
    "print(\"5. Random Sample:\")\n",
    "print(sample[['Country', 'Total Waste (Tons)', 'Economic Loss (Million $)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciPy Operation: Pearson Correlation\n",
    "r, p = stats.pearsonr(df_clean['Avg Waste per Capita (Kg)'], df_clean['Economic Loss (Million $)'])\n",
    "print(f\"\\nSciPy Correlation: r = {r:.3f}, p = {p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels: OLS Regression\n",
    "X = sm.add_constant(df_clean['Avg Waste per Capita (Kg)'])\n",
    "y = df_clean['Economic Loss (Million $)']\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(\"\\nStatsmodels OLS Summary:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Histogram of Waste per Capita\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df_clean['Avg Waste per Capita (Kg)'], kde=True, bins=20)\n",
    "plt.title('Distribution of Waste per Capita')\n",
    "plt.xlabel('Kg per Capita')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19694632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Boxplot by Food Category\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Food Category', y='Total Waste (Tons)', data=df_clean)\n",
    "plt.title('Waste by Food Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Visualization: Pairplot\n",
    "sns.pairplot(df_clean[['Total Waste (Tons)', 'Economic Loss (Million $)', 'Avg Waste per Capita (Kg)', 'Population (Million)']])\n",
    "plt.suptitle('Pairwise Relationships', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d93b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot with regression line\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.regplot(x='Total Waste (Tons)', y='Economic Loss (Million $)', data=df_clean,\n",
    "            scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.title('Total Waste vs Economic Loss')\n",
    "plt.xlabel('Total Waste (Tons)')\n",
    "plt.ylabel('Economic Loss (Million $)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae1742",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 0967b63 (initial comit - added capstone file)
